{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "ZFmodel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ_2B0i1KMas",
        "outputId": "6fbbc1ac-7d99-4f13-8f90-cddca3eb9207"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtdkmD5xLj5c",
        "outputId": "f66d1df1-1f7f-45d2-b19a-ab4e253509f8"
      },
      "source": [
        "cd /content/drive/MyDrive/researchPaperAssignment/models/zeiler"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/researchPaperAssignment/models/zeiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSLO6syD4nlN"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import sys\n",
        "sys.path.append(os.path.join('..', '..'))\n",
        "\n",
        "from global_params import *"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaRAsyCd4nlN"
      },
      "source": [
        "batch_size = 200"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G15sQpqNK-k",
        "outputId": "303bcc77-17d8-481c-a58e-4f2c7f657183"
      },
      "source": [
        "!unzip ../../data/train.zip\n",
        "!unzip ../../data/test.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ../../data/train.zip\n",
            "replace train/Claudia_Pechstein/Claudia_Pechstein_0001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  ../../data/test.zip\n",
            "replace test/Claudia_Pechstein/Claudia_Pechstein_0005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtG4V1m14nlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af164fb0-dc8b-4206-8c99-06608edd2772"
      },
      "source": [
        "train_path = os.path.join('train')\n",
        "\n",
        "train_batches = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    # rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ").flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    color_mode='grayscale'\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6352 images belonging to 901 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98PJ7bC-Kxv"
      },
      "source": [
        "#Checkpoint\n",
        "checkpoint_path = \"zeiler_cp.ckpt\"\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)\n",
        "logger_callback = tf.keras.callbacks.CSVLogger(\"history.csv\", append=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pJuNMNJ4nlQ"
      },
      "source": [
        "# Callback for early stopping\n",
        "# es_callback = keras.callbacks.EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     min_delta=0.0001,\n",
        "#     patience=5,\n",
        "#     restore_best_weights=True\n",
        "# )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8aQ3LVb4nlQ"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 70\n",
        "learning_rate = 0.05\n",
        "# Math works out so that one epoch equals one pass through the training data.\n",
        "train_steps_per_epoch = train_batches.n // batch_size"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGlNdCnH4nlQ"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, (7, 7), activation='relu', strides=(2, 2), padding='same', input_shape=input_shape, name='conv1'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool1'),\n",
        "    keras.layers.BatchNormalization(name='norm1'),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv2a'),\n",
        "    keras.layers.Conv2D(192, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv2'),\n",
        "    keras.layers.BatchNormalization(name='norm2'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool2'),\n",
        "    \n",
        "    keras.layers.Conv2D(192, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv3a'),\n",
        "    keras.layers.Conv2D(384, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv3'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool3'),\n",
        "    \n",
        "    keras.layers.Conv2D(384, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv4a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv4'),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv5a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv5'),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv6a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv6'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same', name='pool4'),\n",
        "\n",
        "    keras.layers.Flatten(name='flatten'),\n",
        "    \n",
        "    keras.layers.Dense(1024, name='fc1'),\n",
        "    keras.layers.Dropout(0.2, name='drop1'),\n",
        "    keras.layers.Dense(1024, name='fc2'),\n",
        "    keras.layers.Dropout(0.2, name='drop2'),\n",
        "    keras.layers.Dense(128, name='fc3'),\n",
        "    \n",
        "    keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='l2')\n",
        "], name='zeiler_fergus')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2EzUXi4nlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b2e700-d208-4bb8-8850-6eca64a1afa3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"zeiler_fergus\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 48, 48, 64)        3200      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "norm1 (BatchNormalization)   (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2a (Conv2D)              (None, 24, 24, 64)        4160      \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 24, 24, 192)       110784    \n",
            "_________________________________________________________________\n",
            "norm2 (BatchNormalization)   (None, 24, 24, 192)       768       \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 12, 12, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv3a (Conv2D)              (None, 12, 12, 192)       37056     \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 12, 12, 384)       663936    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv4a (Conv2D)              (None, 6, 6, 384)         147840    \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 6, 6, 256)         884992    \n",
            "_________________________________________________________________\n",
            "conv5a (Conv2D)              (None, 6, 6, 256)         65792     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv6a (Conv2D)              (None, 6, 6, 256)         65792     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "drop1 (Dropout)              (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "fc3 (Dense)                  (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "l2 (Lambda)                  (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 6,705,856\n",
            "Trainable params: 6,705,344\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMK5U3nH4nlR"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=0.2)\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRu6dKz4nlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a03563-0763-4522-f06a-39ba7fbcfd1e"
      },
      "source": [
        "# %%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    callbacks=[cp_callback, logger_callback]\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1962\n",
            "Epoch 00001: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.1962\n",
            "Epoch 2/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1935\n",
            "Epoch 00002: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.1935\n",
            "Epoch 3/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1933\n",
            "Epoch 00003: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1933\n",
            "Epoch 4/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1921\n",
            "Epoch 00004: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1921\n",
            "Epoch 5/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1917\n",
            "Epoch 00005: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1917\n",
            "Epoch 6/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1922\n",
            "Epoch 00006: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 246s 8s/step - loss: 0.1922\n",
            "Epoch 7/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1887\n",
            "Epoch 00007: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1887\n",
            "Epoch 8/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1844\n",
            "Epoch 00008: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1844\n",
            "Epoch 9/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1832\n",
            "Epoch 00009: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.1832\n",
            "Epoch 10/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1788\n",
            "Epoch 00010: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.1788\n",
            "Epoch 11/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1772\n",
            "Epoch 00011: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.1772\n",
            "Epoch 12/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1739\n",
            "Epoch 00012: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1739\n",
            "Epoch 13/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1643\n",
            "Epoch 00013: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1643\n",
            "Epoch 14/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1714\n",
            "Epoch 00014: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1714\n",
            "Epoch 15/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1585\n",
            "Epoch 00015: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1585\n",
            "Epoch 16/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1535\n",
            "Epoch 00016: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 247s 8s/step - loss: 0.1535\n",
            "Epoch 17/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1429\n",
            "Epoch 00017: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.1429\n",
            "Epoch 18/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1321\n",
            "Epoch 00018: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1321\n",
            "Epoch 19/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1313\n",
            "Epoch 00019: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 237s 8s/step - loss: 0.1313\n",
            "Epoch 20/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1185\n",
            "Epoch 00020: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 237s 8s/step - loss: 0.1185\n",
            "Epoch 21/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1253\n",
            "Epoch 00021: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.1253\n",
            "Epoch 22/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1046\n",
            "Epoch 00022: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1046\n",
            "Epoch 23/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1066\n",
            "Epoch 00023: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.1066\n",
            "Epoch 24/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1022\n",
            "Epoch 00024: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.1022\n",
            "Epoch 25/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0915\n",
            "Epoch 00025: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.0915\n",
            "Epoch 26/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0974\n",
            "Epoch 00026: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 238s 8s/step - loss: 0.0974\n",
            "Epoch 27/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0930\n",
            "Epoch 00027: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0930\n",
            "Epoch 28/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0859\n",
            "Epoch 00028: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0859\n",
            "Epoch 29/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0875\n",
            "Epoch 00029: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 238s 8s/step - loss: 0.0875\n",
            "Epoch 30/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0771\n",
            "Epoch 00030: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.0771\n",
            "Epoch 31/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0754\n",
            "Epoch 00031: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0754\n",
            "Epoch 32/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0767\n",
            "Epoch 00032: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0767\n",
            "Epoch 33/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0768\n",
            "Epoch 00033: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.0768\n",
            "Epoch 34/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0771\n",
            "Epoch 00034: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0771\n",
            "Epoch 35/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1014\n",
            "Epoch 00035: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.1014\n",
            "Epoch 36/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0673\n",
            "Epoch 00036: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 238s 8s/step - loss: 0.0673\n",
            "Epoch 37/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0693\n",
            "Epoch 00037: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0693\n",
            "Epoch 38/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0629\n",
            "Epoch 00038: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0629\n",
            "Epoch 39/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0633\n",
            "Epoch 00039: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0633\n",
            "Epoch 40/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0568\n",
            "Epoch 00040: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.0568\n",
            "Epoch 41/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0579\n",
            "Epoch 00041: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0579\n",
            "Epoch 42/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0592\n",
            "Epoch 00042: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0592\n",
            "Epoch 43/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0614\n",
            "Epoch 00043: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0614\n",
            "Epoch 44/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0617\n",
            "Epoch 00044: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.0617\n",
            "Epoch 45/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0637\n",
            "Epoch 00045: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 245s 8s/step - loss: 0.0637\n",
            "Epoch 46/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0610\n",
            "Epoch 00046: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.0610\n",
            "Epoch 47/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0567\n",
            "Epoch 00047: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 245s 8s/step - loss: 0.0567\n",
            "Epoch 48/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0545\n",
            "Epoch 00048: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 238s 8s/step - loss: 0.0545\n",
            "Epoch 49/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0542\n",
            "Epoch 00049: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0542\n",
            "Epoch 50/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0613\n",
            "Epoch 00050: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 248s 8s/step - loss: 0.0613\n",
            "Epoch 51/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0570\n",
            "Epoch 00051: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0570\n",
            "Epoch 52/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0596\n",
            "Epoch 00052: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 246s 8s/step - loss: 0.0596\n",
            "Epoch 53/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0631\n",
            "Epoch 00053: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0631\n",
            "Epoch 54/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0531\n",
            "Epoch 00054: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.0531\n",
            "Epoch 55/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0505\n",
            "Epoch 00055: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 247s 8s/step - loss: 0.0505\n",
            "Epoch 56/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0530\n",
            "Epoch 00056: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.0530\n",
            "Epoch 57/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0524\n",
            "Epoch 00057: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0524\n",
            "Epoch 58/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0470\n",
            "Epoch 00058: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0470\n",
            "Epoch 59/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0455\n",
            "Epoch 00059: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.0455\n",
            "Epoch 60/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0489\n",
            "Epoch 00060: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0489\n",
            "Epoch 61/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0474\n",
            "Epoch 00061: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0474\n",
            "Epoch 62/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0541\n",
            "Epoch 00062: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.0541\n",
            "Epoch 63/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0469\n",
            "Epoch 00063: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 239s 8s/step - loss: 0.0469\n",
            "Epoch 64/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0446\n",
            "Epoch 00064: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 243s 8s/step - loss: 0.0446\n",
            "Epoch 65/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0427\n",
            "Epoch 00065: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 238s 8s/step - loss: 0.0427\n",
            "Epoch 66/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0456\n",
            "Epoch 00066: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 241s 8s/step - loss: 0.0456\n",
            "Epoch 67/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0383\n",
            "Epoch 00067: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 242s 8s/step - loss: 0.0383\n",
            "Epoch 68/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0535\n",
            "Epoch 00068: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0535\n",
            "Epoch 69/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0435\n",
            "Epoch 00069: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 244s 8s/step - loss: 0.0435\n",
            "Epoch 70/70\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0430\n",
            "Epoch 00070: saving model to zeiler_cp.ckpt\n",
            "INFO:tensorflow:Assets written to: zeiler_cp.ckpt/assets\n",
            "31/31 [==============================] - 240s 8s/step - loss: 0.0430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vrVLYrF_DXD"
      },
      "source": [
        "#get the latest checkpoint file\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "#Create a new model instance\n",
        "model_latest_checkpoint = create_model()\n",
        "# Load the previously saved weights\n",
        "model_latest_checkpoint.load_weights(latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFaVqWmr7S-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633958b8-ad08-4bae-a69f-7bb441d1fcdc"
      },
      "source": [
        "test_path = 'test'\n",
        "\n",
        "test_batches = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1/255\n",
        ").flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    color_mode='grayscale'\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1254 images belonging to 901 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYPi_2c7Ngr"
      },
      "source": [
        "# Evaluate the network\n",
        "results = model.predict(test_batches)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_TORYUP7O8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2326a3ad-8ad1-41fd-ef81-96cada960178"
      },
      "source": [
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "\"\"\"\n",
        "x=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
        "y=np.concatenate([train_generator.next()[1] for i in range(train_generator.__len__())])\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "y = y.astype(int)\n",
        "\n",
        "import io\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for img, label in tfds.as_numpy(test_batches):\n",
        "    [out_m.write(str(label) + \"\\n\")]\n",
        "out_m.close()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  # files.download('meta.tsv')\n",
        "except:\n",
        "  pass\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_84c800a7-7b31-4fe4-9eec-bf12a338fb1a\", \"vecs.tsv\", 4095664)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyhCxbsl4nlS"
      },
      "source": [
        "# %%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE5_80xE4nlS"
      },
      "source": [
        "# %%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "with open('history.pickle', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK2DjeD24nlS"
      },
      "source": [
        "model = keras.models.load_model('model.h5')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u26835cq4nlS"
      },
      "source": [
        "with open('history.pickle', 'rb') as f:\n",
        "    history = pickle.load(f)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "s8H372VNfUQR",
        "outputId": "c1209315-a815-4331-93fc-8aba6c383587"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel(r'Triplet Loss $(\\alpha=0.2)$')\n",
        "plt.plot(np.arange(1, len(history['loss']) + 1), history['loss'], color='b');"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}