{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "ZFmodel.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEabdZLy5Y0p"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSLO6syD4nlN"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import sys\n",
        "# sys.path.append(os.path.join('..', '..'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOJtJ9Bp4nlN"
      },
      "source": [
        "# Seed for all PRNGs used in this assignment.\n",
        "SEED = 1\n",
        "\n",
        "# ---------- TRAIN-TEST SPLIT ----------\n",
        "# Minimum number of images per class to consider for train and test.\n",
        "min_img_per_class = 3\n",
        "# If class contains min_img_per_class, fraction of total images in class to keep for testing.\n",
        "test_frac = 0.2\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaRAsyCd4nlN"
      },
      "source": [
        "target_size = (220, 220)\n",
        "batch_size = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtG4V1m14nlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3526e93a-c523-4d80-d00c-2699095470b4"
      },
      "source": [
        "train_path = os.path.join('data', 'train')\n",
        "\n",
        "train_batches = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        "    # rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ").flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5783 images belonging to 901 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98PJ7bC-Kxv"
      },
      "source": [
        "#Checkpoint\n",
        "checkpoint_path = \"train_ckpt/cp.ckpt\"\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pJuNMNJ4nlQ"
      },
      "source": [
        "# Callback for early stopping\n",
        "# es_callback = keras.callbacks.EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     min_delta=0.0001,\n",
        "#     patience=5,\n",
        "#     restore_best_weights=True\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8aQ3LVb4nlQ"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 20\n",
        "learning_rate = 0.03\n",
        "validation_split = 0.1\n",
        "# Math works out so that one epoch equals one pass through the training data.\n",
        "train_steps_per_epoch = train_batches.n // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGlNdCnH4nlQ"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, (7, 7), activation='relu', strides=(2, 2), padding='same', input_shape=(target_size[0], target_size[1], 3), name='conv1'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool1'),\n",
        "    keras.layers.BatchNormalization(name='norm1'),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv2a'),\n",
        "    keras.layers.Conv2D(192, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv2'),\n",
        "    keras.layers.BatchNormalization(name='norm2'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool2'),\n",
        "    \n",
        "    keras.layers.Conv2D(192, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv3a'),\n",
        "    keras.layers.Conv2D(384, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv3'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool3'),\n",
        "    \n",
        "    keras.layers.Conv2D(384, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv4a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv4'),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv5a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv5'),\n",
        "    \n",
        "    keras.layers.Conv2D(256, (1, 1), activation='relu', strides=(1, 1), padding='same', name='conv6a'),\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(1, 1), padding='same', name='conv6'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same', name='pool4'),\n",
        "\n",
        "    keras.layers.Flatten(name='flatten'),\n",
        "    \n",
        "    keras.layers.Dense(32 * 128, activation='relu', name='fc1'),\n",
        "    keras.layers.Dropout(0.2, name='drop1'),\n",
        "    keras.layers.Dense(32 * 128, activation='relu', name='fc2'),\n",
        "    keras.layers.Dropout(0.2, name='drop2'),\n",
        "    keras.layers.Dense(128, activation='relu', name='fc3'),\n",
        "    \n",
        "    keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='l2')\n",
        "], name='zeiler_fergus')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2EzUXi4nlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fff7cf2-ccef-45af-cc90-4daac1b4fa0d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"zeiler_fergus\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 110, 110, 64)      9472      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "norm1 (BatchNormalization)   (None, 55, 55, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2a (Conv2D)              (None, 55, 55, 64)        4160      \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 55, 55, 192)       110784    \n",
            "_________________________________________________________________\n",
            "norm2 (BatchNormalization)   (None, 55, 55, 192)       768       \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 28, 28, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv3a (Conv2D)              (None, 28, 28, 192)       37056     \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 28, 28, 384)       663936    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 14, 14, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv4a (Conv2D)              (None, 14, 14, 384)       147840    \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 14, 14, 256)       884992    \n",
            "_________________________________________________________________\n",
            "conv5a (Conv2D)              (None, 14, 14, 256)       65792     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 14, 14, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv6a (Conv2D)              (None, 14, 14, 256)       65792     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 14, 14, 256)       590080    \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              51384320  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc3 (Dense)                  (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "l2 (Lambda)                  (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 71,861,056\n",
            "Trainable params: 71,860,544\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMK5U3nH4nlR"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=0.2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRu6dKz4nlR"
      },
      "source": [
        "# %%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    callbacks=[cp_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vrVLYrF_DXD"
      },
      "source": [
        "#get the latest checkpoint file\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "#Create a new model instance\n",
        "model_latest_checkpoint = create_model()\n",
        "# Load the previously saved weights\n",
        "model_latest_checkpoint.load_weights(latest)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFaVqWmr7S-6"
      },
      "source": [
        "test_path = os.path.join('data', 'test')\n",
        "\n",
        "train_batches = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1/255\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1\n",
        ").flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYPi_2c7Ngr"
      },
      "source": [
        "# Evaluate the network\n",
        "results = model.predict(test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_TORYUP7O8C"
      },
      "source": [
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "x=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
        "y=np.concatenate([train_generator.next()[1] for i in range(train_generator.__len__())])\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "y = y.astype(int)\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for img, label in zip(test_batches):\n",
        "    [out_m.write(str(label) + \"\\n\")]\n",
        "out_m.close()\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n",
        "except:\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyhCxbsl4nlS"
      },
      "source": [
        "%%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE5_80xE4nlS"
      },
      "source": [
        "%%script echo \"Comment line with %%script echo to run this cell.\"\n",
        "\n",
        "with open('history.pickle', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK2DjeD24nlS"
      },
      "source": [
        "model = keras.models.load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u26835cq4nlS"
      },
      "source": [
        "with open('history.pickle', 'rb') as f:\n",
        "    history = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}